{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ba6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from contextlib import contextmanager\n",
    "import logging\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, average_precision_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, KFold,GroupKFold,StratifiedGroupKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder\n",
    "from torch.nn import TransformerDecoder\n",
    "from torch.nn import LayerNorm\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import gc\n",
    "import random\n",
    "import os\n",
    "%matplotlib inline\n",
    "import logging\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7baabbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "exp = \"001\"\n",
    "if not os.path.exists(f\"../out/exp/exp{exp}\"):\n",
    "    os.makedirs(f\"../out/exp/exp{exp}\")\n",
    "    os.makedirs(f\"../out/exp/exp{exp}/exp{exp}_model\")\n",
    "logger_path = f\"../out/exp/exp{exp}/exp_{exp}.txt\"\n",
    "model_path =f\"../out/exp/exp{exp}/exp{exp}_model/exp{exp}.pth\"\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "file_handler = logging.FileHandler(logger_path)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "LOGGER.addHandler(file_handler)\n",
    "\n",
    "# config\n",
    "seed = 0\n",
    "shuffle = True\n",
    "n_splits = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model config\n",
    "batch_size = 24\n",
    "n_epochs = 5\n",
    "lr = 1e-3\n",
    "weight_decay = 0.05\n",
    "num_warmup_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61df6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_path = f\"../out/fe/fe001/id_list.npy\"\n",
    "player_path = f\"../out/fe/fe001/player_list.npy\"\n",
    "feature_arr_path = f\"../out/fe/fe001/feature_arr.npy\"\n",
    "target_arr_path = f\"../out/fe/fe001/target_arr.npy\"\n",
    "mask_arr_path = f\"../out/fe/fe001/mask_arr.npy\"\n",
    "target_mask_arr_path = f\"../out/fe/fe001/target_mask_arr.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "740a6086",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_arr = np.load(feature_arr_path)\n",
    "target_arr = np.load(target_arr_path)\n",
    "mask_arr = np.load(mask_arr_path)\n",
    "target_mask_arr =np.load(target_mask_arr_path)\n",
    "id_list = np.load(id_path)\n",
    "player_list = np.load(player_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a048c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18361, 500, 24)\n",
      "(18361, 500, 11)\n",
      "(18361, 500)\n",
      "(18361, 500, 11)\n",
      "(18361,)\n",
      "(18361,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
       "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
       "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
       "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
       "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
       "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(feature_arr.shape)\n",
    "print(target_arr.shape)\n",
    "print(mask_arr.shape)\n",
    "print(target_mask_arr.shape)\n",
    "print(id_list.shape)\n",
    "print(player_list.shape)\n",
    "player_list[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "840722b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early mix (current)\n",
    "# mid mix\n",
    "# late mix (patchTST)\n",
    "# patch transfromer (GRU + transformer), (transformer + GRU) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbcb3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwingDataset(Dataset):\n",
    "    def __init__(self, feature_arr, \n",
    "                 mask_arr,\n",
    "                 train = True, y = None, target_mask = None):\n",
    "        self.feature_arr = feature_arr\n",
    "        self.mask_arr = mask_arr\n",
    "        self.train = train\n",
    "        self.y = y\n",
    "        self.target_mask = target_mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.feature_arr)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        attention_mask = self.mask_arr[idx] == 0\n",
    "\n",
    "        if self.train : \n",
    "            return {\n",
    "              'feature_arr': torch.tensor(self.feature_arr[idx],dtype=torch.float32),\n",
    "              'mask_arr':torch.tensor(self.mask_arr[idx], dtype=torch.long),  \n",
    "            #   'attention_mask': torch.tensor(attention_mask, dtype=torch.bool),\n",
    "              \"y\":torch.tensor(self.y[idx], dtype=torch.long)\n",
    "               }\n",
    "        else:\n",
    "            return {\n",
    "              'feature_arr': torch.tensor(self.feature_arr[idx],dtype=torch.float32),\n",
    "              'mask_arr':torch.tensor(self.mask_arr[idx], dtype=torch.long),  \n",
    "            #   'attention_mask': torch.tensor(attention_mask, dtype=torch.bool),\n",
    "               }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d42b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwingGRU(nn.Module):\n",
    "    def __init__(\n",
    "        self, dropout=0.2,\n",
    "        input_numerical_size = 24,\n",
    "        numeraical_linear_size = 64,\n",
    "        model_size = 128,\n",
    "        linear_out = 128,\n",
    "        out_size=11):\n",
    "        super(SwingGRU, self).__init__()\n",
    "        self.numerical_linear  = nn.Sequential(\n",
    "                nn.Linear(input_numerical_size, numeraical_linear_size),\n",
    "                nn.LayerNorm(numeraical_linear_size)\n",
    "            )\n",
    "        \n",
    "        self.rnn = nn.GRU(numeraical_linear_size, model_size,\n",
    "                            num_layers = 2, \n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        \n",
    "        \n",
    "                \n",
    "        self.linear_out  = nn.Sequential(\n",
    "                nn.Linear(model_size*2, \n",
    "                          linear_out),\n",
    "                nn.LayerNorm(linear_out),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(linear_out, \n",
    "                          out_size))\n",
    "        self._reinitialize()\n",
    "        \n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'rnn' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "    \n",
    "    def forward(self, numerical_array):\n",
    "        \n",
    "        numerical_embedding = self.numerical_linear(numerical_array)\n",
    "        output,_ = self.rnn(numerical_embedding)\n",
    "        output = self.linear_out(output[:, -1, :])\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d01f4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield \n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "956868ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by level\n",
    "target_labels = target_arr[:, 0, -4:]\n",
    "target_labels = np.argmax(target_labels, axis=1)\n",
    "# group by year\n",
    "# target_labels = target_arr[:, 0, 4:7]\n",
    "# target_labels = np.argmax(target_labels, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9220806",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = StratifiedGroupKFold(n_splits=5,shuffle=True,random_state = seed)\n",
    "iterator = gkf.split(feature_arr, y = target_labels, groups= player_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58ec6a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SwingDataset(feature_arr, mask_arr, train=True, y = target_arr, target_mask=target_mask_arr)\n",
    "train_loader = DataLoader(train_ds, batch_size=2, pin_memory=True, num_workers=4)\n",
    "X = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18933793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['feature_arr', 'mask_arr', 'y'])\n",
      "torch.Size([2, 500, 24])\n",
      "torch.Size([2, 500])\n",
      "torch.Size([2, 500, 11])\n"
     ]
    }
   ],
   "source": [
    "print(X.keys())\n",
    "print(X['feature_arr'].shape)\n",
    "print(X['mask_arr'].shape)\n",
    "# print(X['attention_mask'].shape)\n",
    "# print(X['target_mask'].shape)\n",
    "print(X['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62577b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998795600000001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.62496989 - 0.5) * 4 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66041b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SwingGRU()\n",
    "X = torch.randn((2, 100, 24))\n",
    "y = model(X)\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d8f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69c9441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2e7a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_mask, y = d['feature_arr'], d['mask_arr'], d['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09ef2cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7225, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "[[0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]]\n",
      "[[0.6139204  0.48410693 0.461842   0.65950394]\n",
      " [0.629697   0.53958386 0.50846887 0.55952424]\n",
      " [0.5945234  0.5363443  0.5661934  0.5703213 ]\n",
      " [0.624775   0.5706702  0.44688225 0.5274387 ]\n",
      " [0.6150585  0.4953904  0.5827365  0.59241873]\n",
      " [0.7358353  0.6104891  0.4725673  0.5590229 ]\n",
      " [0.60574275 0.5496781  0.50589293 0.55996925]\n",
      " [0.64458054 0.5704017  0.57075834 0.43976256]\n",
      " [0.67575556 0.5435472  0.4838261  0.5121095 ]\n",
      " [0.5768638  0.480682   0.4759126  0.4649096 ]]\n",
      "0.5362476666666667\n"
     ]
    }
   ],
   "source": [
    "X, X_mask, y = d['feature_arr'], d['mask_arr'], d['y']\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "output = model(X)\n",
    "loss = criterion(output[:, 100:], y[:, 100:].float())\n",
    "print(loss)\n",
    "prob = F.sigmoid(output).flatten(end_dim=1).detach().numpy()\n",
    "y = y.flatten(end_dim=1).detach().numpy()\n",
    "print(y[:10, -4:])\n",
    "print(prob[:10, -4:])\n",
    "\n",
    "level_score = roc_auc_score(y[:, -4:], prob[:, -4:], average='micro', multi_class='ovr')\n",
    "print(level_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2464f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129359cc7bf94fb5831071e4fbb6ca83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1699, level score: 0.9475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afe3c16f09a4de38c08714375f1cdc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.6603, level score: 0.7958\n",
      "(2060000, 11) (2060000, 11)\n",
      "Confusion Matrix:\n",
      "[[443699   9852  62427 340656]\n",
      " [     0      0      0      0]\n",
      " [128486     35    852  50168]\n",
      " [140870   4593   1383 876979]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e3874d335340a9ac4bb6b9d7d79b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0196, level score: 0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09eaaa0d3134189bafd86f580001dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.8931, level score: 0.7970\n",
      "(2060000, 11) (2060000, 11)\n",
      "Confusion Matrix:\n",
      "[[465342  13166  32039 346087]\n",
      " [     0      0      0      0]\n",
      " [145469    138    417  33517]\n",
      " [138139  12978   4761 867947]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb9142fc04e40048ed79e66dae2516b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0066, level score: 0.9999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af11fcd10c84ffdad07433eac8eb99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.8548, level score: 0.8115\n",
      "(2060000, 11) (2060000, 11)\n",
      "Confusion Matrix:\n",
      "[[596569  17383  43789 198893]\n",
      " [     0      0      0      0]\n",
      " [163847    184     34  15476]\n",
      " [189512  59650   7531 767132]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72459692468400c976fa51fe10efd14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0028, level score: 1.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0f72bb304e4c7f80276b36d8aa1052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.9791, level score: 0.7842\n",
      "(2060000, 11) (2060000, 11)\n",
      "Confusion Matrix:\n",
      "[[493106  38292  46208 279028]\n",
      " [     0      0      0      0]\n",
      " [147305    485     72  31679]\n",
      " [158644  17863   2909 844409]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb0d083a6f249708b2b63da20e76e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0016, level score: 1.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68ce19816bc47e6b9bb0d78146c92d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1.0044, level score: 0.8032\n",
      "(2060000, 11) (2060000, 11)\n",
      "Confusion Matrix:\n",
      "[[532840  17704  42629 263461]\n",
      " [     0      0      0      0]\n",
      " [153606    131      4  25800]\n",
      " [179564  12300   2690 829271]]\n"
     ]
    }
   ],
   "source": [
    "with timer('TTGRU'):\n",
    "    for fold, (train_idx, val_idx) in enumerate(iterator):\n",
    "        LOGGER.info(f\"start fold:{fold}, train size: {len(train_idx)}, val size: {len(val_idx)}\")\n",
    "        with timer(f\"fold {fold}\"):\n",
    "            \n",
    "            train_feature = feature_arr[train_idx]\n",
    "            train_target = target_arr[train_idx]\n",
    "            train_mask = mask_arr[train_idx]\n",
    "            \n",
    "            val_feature = feature_arr[val_idx]\n",
    "            val_target = target_arr[val_idx]\n",
    "            val_mask = mask_arr[val_idx]\n",
    "\n",
    "            train_ds = SwingDataset(train_feature, train_mask, train=True, y = train_target)\n",
    "            val_ds = SwingDataset(val_feature, val_mask, train=True, y = val_target)\n",
    "            train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "            val_loader = DataLoader(val_ds, batch_size=batch_size, pin_memory=True, num_workers=4)\n",
    "            \n",
    "            \n",
    "            model = SwingGRU()\n",
    "            model = model.to(device)\n",
    "            param_optimizer = list(model.named_parameters())\n",
    "            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "            optimizer_grouped_parameters = [\n",
    "                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
    "                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "            ]\n",
    "            optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                              lr=lr,\n",
    "                              weight_decay=weight_decay,\n",
    "                              )\n",
    "            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n",
    "            scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                        num_warmup_steps=num_warmup_steps,\n",
    "                                                        num_training_steps=num_train_optimization_steps)\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            best_val_score = 0\n",
    "            \n",
    "            for epoch in range(n_epochs):                \n",
    "                model.train() \n",
    "                train_losses_batch = []\n",
    "                train_score_batch = []\n",
    "                val_losses_batch = []\n",
    "                val_score_batch = []\n",
    "                epoch_loss = 0\n",
    "                \n",
    "                pbar = tqdm(train_loader, total=len(train_loader), leave = False)\n",
    "                for d in pbar:\n",
    "                    X, X_mask, y = d['feature_arr'].to(device), d['mask_arr'].to(device), d['y'].to(device)\n",
    "                    seq_len = X.shape[1]\n",
    "                    if seq_len <= 100:\n",
    "                        continue\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    output = model(X)\n",
    "                    loss = criterion(output[:, 100:], y[:, 100:].float())\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        prob = F.sigmoid(output).flatten(end_dim=1).detach().cpu().numpy()\n",
    "                        y = y.flatten(end_dim=1).detach().cpu().numpy()\n",
    "                        \n",
    "                        level_score = roc_auc_score(y[:, -4:], prob[:, -4:], average='micro', multi_class='ovr')\n",
    "\n",
    "                    \n",
    "                    train_losses_batch.append(loss.item())\n",
    "                    train_score_batch.append(level_score)\n",
    "                    \n",
    "                train_loss = np.mean(train_losses_batch)\n",
    "                train_score = np.mean(train_score_batch)\n",
    "                print(f\"train loss: {train_loss:.4f}, level score: {train_score:.4f}\")\n",
    "                \n",
    "                model.eval()\n",
    "                ys = []\n",
    "                probs = []\n",
    "                pbar = tqdm(val_loader, total=len(val_loader), leave=False)\n",
    "                with torch.no_grad():\n",
    "                    for d in pbar:\n",
    "                        X, X_mask, y = d['feature_arr'].to(device), d['mask_arr'].to(device), d['y'].to(device)\n",
    "                        seq_len = X.shape[1]\n",
    "                        if seq_len <= 100:\n",
    "                            continue\n",
    "                                                \n",
    "                        output = model(X)\n",
    "                        loss = criterion(output[:, 100:], y[:, 100:].float())\n",
    "                        \n",
    "                        prob = F.sigmoid(output).flatten(end_dim=1).cpu().numpy()\n",
    "                        y = y.flatten(end_dim=1).cpu().numpy()\n",
    "                        ys.append(y)\n",
    "                        probs.append(prob)\n",
    "                        \n",
    "                        level_score = roc_auc_score(y[:, -4:], prob[:, -4:], average='micro', multi_class='ovr')\n",
    "                        val_losses_batch.append(loss.item())\n",
    "                        val_score_batch.append(level_score)\n",
    "                        \n",
    "                val_loss = np.mean(val_losses_batch)\n",
    "                val_score = np.mean(val_score_batch)\n",
    "                ys = np.concatenate(ys)\n",
    "                probs = np.concatenate(probs)\n",
    "                print(ys.shape, probs.shape)\n",
    "                cm = confusion_matrix(ys[:, -4:].argmax(axis=1), probs[:, -4:].argmax(axis=1))\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43beac89",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ys \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m probs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(probs)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(ys\u001b[38;5;241m.\u001b[39mshape, probs\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "ys = np.concatenate(ys)\n",
    "probs = np.concatenate(probs)\n",
    "print(ys.shape, probs.shape)\n",
    "cm = confusion_matrix(ys[:, -4:].argmax(axis=1), probs[:, -4:].argmax(axis=1))\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
